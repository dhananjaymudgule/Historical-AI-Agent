# Historical AI Agent

## ğŸ“Œ Overview

The **Historical AI Agent** is a **FastAPI-based conversational AI system** using **Agentic Workflow - LangGraph**. It is a conversational bot that has **only the knowledge of historical monuments** across the world. Users can chat with the bot to ask any questions relevant to historical monuments. Within the conversational journey, the bot will be able to **ask for the userâ€™s email address and verify it** by executing the OTP workflow within the chat itself. It supports real-time chat with session-based memory and integrates AI-powered agents for enhanced interactions.

## ğŸš€ Features
- ğŸ› **Historical Knowledge**: The chatbot answers only historical monument-related queries.
- ğŸ’¬ **Conversational AI**: Uses **LangGraph** for structured, session-based interactions.
- ğŸ“§ **Email Verification**: Bot asks for and verifies email via OTP during the chat.
- ğŸ”„ **Session-Based Memory**: Retains chat history for contextual conversations.
- âš¡ **FastAPI Backend**: Efficient and scalable API framework.
- ğŸŒ **Web UI**: Interactive frontend using **Streamlit**.
- ğŸ”’ **CORS Enabled**: Allows secure communication between frontend and backend.
- ğŸ›  **Modular & Scalable**: Well-structured, extensible architecture.
- âœ… **Automated Testing**: Ensures system stability with Pytest.

## ğŸ— Directory Structure
```
HISTORICAL-AI-AGENT/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py         # Chatbot endpoint (LangGraph-based)
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py        # AI agent endpoint (LangGraph-based)
â”‚   â”‚â”€â”€ chat_ui/
â”‚   â”‚   â”œâ”€â”€ app.py              # Streamlit UI
â”‚   â”‚â”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # App settings & environment variables
â”‚   â”‚â”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py             # User model (if needed)
â”‚   â”‚â”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ chatbot_prompts.py  # System prompts for the chatbot
â”‚   â”‚â”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ chat.py             # Pydantic models for request/response validation
â”‚   â”‚â”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat_service.py     # Handles chat interactions with LangGraph
â”‚   â”‚   â”œâ”€â”€ agent_service.py    # Manages AI agent responses
â”‚   â”‚   â”œâ”€â”€ email_service.py    # Handles OTP-based email verification
â”‚   â”‚â”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_chat.py        # Tests for chat service
â”‚   â”‚â”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ otp.py              # OTP-related functions
â”‚â”€â”€ main.py                     # FastAPI entry point
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ Dockerfile                  # Containerization setup
â”‚â”€â”€ README.md                   # Project documentation
```

## ğŸ“¦ Installation & Setup

### **1ï¸âƒ£ Create Virtual Environment**
```bash
python -m venv venv
venv\Scripts\activate  # On Windows
source venv/bin/activate  # On Mac/Linux
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up Environment Variables**
Create a `.env` file in the project root by referring to `.env.example` and update it with your credentials.

```ini
# API Configuration
VERSION=1.0.0
HOST=127.0.0.1
PORT=8000
PROJECT_NAME="Historical Monuments Bot"
PROJECT_DESCRIPTION="Historical Monuments Bot"

# Email Configuration
EMAIL_SENDER=your_email@example.com
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_PASSWORD=your_email_password

# AI Model Configuration
GEMINI_LLM_MODEL_NAME=gemini-2.0-flash
GEMINI_API_KEY=your_gemini_api_key_here
```

## ğŸƒâ€â™‚ï¸ Running the Project

### **1ï¸âƒ£ Start FastAPI Backend**
```bash
uvicorn app.main:app --reload
```
- **Swagger UI (API Docs)** â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **Redoc UI** â†’ [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)
- **Health Check** â†’ [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

### **2ï¸âƒ£ Start Streamlit Frontend**
```bash
cd app/chat_ui
streamlit run app.py
```

## ğŸ›  API Endpoints
### **1ï¸âƒ£ Chat API (`chat.py`)**
| Method | Endpoint | Description |
|--------|---------|-------------|
| `POST` | `/chat` | Handles chatbot interactions via LangGraph |

### **2ï¸âƒ£ AI Agent API (`agent.py`)**
| Method | Endpoint | Description |
|--------|---------|-------------|
| `POST` | `/agent` | LangGraph-based AI agent handling historical monument queries and OTP verification |

## ğŸ— Project Architecture
### **ğŸ”¹ 1ï¸âƒ£ API Layer (`api/routes/`)**
- **`chat.py`** â†’ Handles chatbot interactions.
- **`agent.py`** â†’ Processes AI agent interactions.

### **ğŸ”¹ 2ï¸âƒ£ Business Logic (`services/`)**
- **`chat_service.py`** â†’ Manages chat history & processing.
- **`agent_service.py`** â†’ Manages AI agent logic.
- **`email_service.py`** â†’ Handles OTP-based email verification.

### **ğŸ”¹ 3ï¸âƒ£ Prompt Management (`prompts/`)**
- **`chatbot_prompts.py`** â†’ Stores system and user prompts.

### **ğŸ”¹ 4ï¸âƒ£ Utilities (`utils/`)**
- **`otp.py`** â†’ OTP-related functions for email verification.

## ğŸ¯ Future Enhancements
- âœ… Improve **multi-turn conversation handling**.
- âœ… Add **database storage for chat history**.
- âœ… Implement **better response ranking and retrieval**.
- âœ… Deploy on **AWS/GCP with CI/CD automation**.

## ğŸ“œ License
This project is licensed under the **License**.

---


